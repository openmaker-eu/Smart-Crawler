## Volatile Multi-Armed Bandits for Guaranteed Targeted Social Crawling
### Abstract
We introduce a new variant of the multi-armed bandit prob- lem, called Volatile Multi-Arm Bandit (VMAB). A general policy for VMAB is given with proven regret bounds. The problem of collecting intelligence on profiles in social net- works is then modeled as a VMAB and experimental results show the superiority of our proposed policy.
### Summary
...

## Bandit Algorithms for Social Network Queries
### Abstract
In many cases the best way to find a profile or a set of profiles matching some criteria in a social network is via targeted crawling. An important challenge in targeted crawling is to choose the next profile to explore. Existing heuristics for targeted crawling are usually tailored for specific search criterion and could lead to short-sighted crawling decisions. In this paper we propose and evaluate a generic approach for guiding a social network crawler that aims to provide a proper balance between exploration and exploitation based on the recently introduced variant of the Multi-Armed Bandit problem with volatile arms (VMAB). Our approach is general-purpose. In addition, it provides provable performance guarantees. Experimental results indicate that our approach compares favorably with the best existing heuristics on two different domains.
### Summary
...

## Social Network Search as a Volatile Multi-armed Bandit Problem
### Abstract
In many cases the best way to find a profile or a set of profiles matching some criteria in a social network is via targeted crawling. An important chal- lenge in targeted crawling is choosing the next profile to explore. Existing heuristics for targeted crawl- ing are usually tailored for specific search criterion and could lead to short-sighted crawling decisions. In this paper we propose and evaluate a generic ap- proach for guiding targeted crawling which is based on recent developments in Artificial Intelligence. Our approach, based on the recently introduced variant of the Multi-Armed Bandit problem with volatile arms (VMAB), aims to provide a proper balance between exploration and exploitation during the crawling pro- cess. Unlike other heuristics which are hand tailored for specific type of search queries, our approach is general-purpose. In addition, it provides provable performance guarantees. Experimental results indi- cate that our approach compares favorably with the best existing heuristics on two different domains.
### Summary
...

## Information Gathering in Networks via Active Exploration (+)
### Abstract
How should we gather information in a network, where each node's visibility is limited to its local neighborhood? This problem arises in numerous real-world applications, such as surveying and task routing in social networks, team formation in collaborative networks and experimental design with dependency constraints. Often the informativeness of a set of nodes can be quantified via a submodular utility function. Existing approaches for submodular optimization, however, require that the set of all nodes that can be selected is known ahead of time, which is often unrealistic. In contrast, we propose a novel model where we start our exploration from an initial node, and new nodes become visible and available for selection only once one of their neighbors has been chosen. We then present a general algorithm NetExp for this problem, and provide theoretical bounds on its performance dependent on structural properties of the underlying network. We evaluate our methodology on various simulated problem instances as well as on data collected from social question answering system deployed within a large enterprise.
### Summary
...

## Online Influence Maximization under Independent Cascade Model with Semi-Bandit Feedback
### Abstract
We study the online influence maximization problem in social networks under the independent cascade model. Specifically, we aim to learn the set of "best influencers" in a social network online while repeatedly interacting with it. We address the challenges of (i) combinatorial action space, since the number of feasible influencer sets grows exponentially with the maximum number of influencers, and (ii) limited feedback, since only the influenced portion of the network is observed. Under a stochastic semi-bandit feedback, we propose and analyze IMLinUCB, a computationally efficient UCB-based algorithm. Our bounds on the cumulative regret are polynomial in all quantities of interest, achieve near-optimal dependence on the number of interactions and reflect the topology of the network and the activation probabilities of its edges, thereby giving insights on the problem complexity. To the best of our knowledge, these are the first such results. Our experiments show that in several representative graph topologies, the regret of IMLinUCB scales as suggested by our upper bounds. IMLinUCB permits linear generalization and thus is both statistically and computationally suitable for large-scale problems. Our experiments also show that IMLinUCB with linear generalization can lead to low regret in real-world online influence maximization.
### Summary
...

## Revealing Graph Bandits for Maximizing Local Influence
### Abstract
We study a graph bandit setting where the objective of the learner is to detect the most influential node of a graph by requesting as little information from the graph as possible. One of the relevant applications for this set- ting is marketing in social networks, where the marketer aims at finding and taking ad- vantage of the most influential customers. The existing approaches for bandit problems on graphs require either partial or complete knowledge of the graph. In this paper, we do not assume any knowledge of the graph, but we consider a setting where it can be gradu- ally discovered in a sequential and active way. At each round, the learner chooses a node of the graph and the only information it receives is a stochastic set of the nodes that the chosen node is currently influencing. To address this setting, we propose BARE, a bandit strategy for which we prove a regret guarantee that scales with the detectable dimension, a prob- lem dependent quantity that is often much smaller than the number of nodes.
### Summary
...

## Networked Bandits with disjoint linear payoffs
### Abstract
In this paper, we study 'networked bandits', a new bandit problem where a set of interrelated arms varies over time and, given the contextual information that selects one arm, invokes other correlated arms. This problem remains under-investigated, in spite of its applicability to many practical problems. For instance, in social networks, an arm can obtain payoffs from both the selected user and its relations since they often share the content through the network. We examine whether it is possible to obtain multiple payoffs from several correlated arms based on the relationships. In particular, we formalize the networked bandit problem and propose an algorithm that considers not only the selected arm, but also the relationships between arms. Our algorithm is 'optimism in face of uncertainty' style, in that it decides an arm depending on integrated confidence sets constructed from historical data. We analyze the performance in simulation experiments and on two real-world offline datasets. The experimental results demonstrate our algorithm's effectiveness in the networked bandit setting.
### Summary
...

## Focused crawling through reinforcement learning
### Abstract
Focused crawling aims at collecting as many Web pages relevant to a target topic as possible while avoiding irrelevant pages, reflecting limited resources available to a Web crawler. We improve on the efficiency of focused crawling by proposing an approach based on reinforcement learning. Our algorithm evaluates hyperlinks most profitable to follow over the long run, and selects the most promising link based on this estimation. To properly model the crawling environment as a Markov decision process, we propose new representations of states and actions considering both content information and the link structure. The size of the state-action space is reduced by a generalization process. Based on this generalization, we use a linear-function approximation to update value functions. We investigate the trade-off between synchronous and asynchronous methods. In experiments, we compare the performance of a crawling task with and without learning; crawlers based on reinforcement learning show better performance for various target topics
### Summary
The authors propose a focused Web crawler that is designed to collect Web pages relevant to a predefined topic. The crawlers main goal is to retrieve as many relevant pages while avoiding irrelevant ones. Relevancy to target topic is defined as cosine similarity between word vector of Web page and word vector of topic. The Web page itself is enough for calculating relevancy. (Unlike Twitter, where a user profile is an abstraction of the user and may not always have enough information for relevancy) They model the crawling environment as an MDP, where Web pages are the states and hyperlinks in a Web page are the actions. State-action value for each hyperlink is computed (called priority in the paper) and all links are added to a priority queue, sorted by priority value.
Database dump of Simple English Wikipedia is used to measure performance of the crawler. They choose 6 target topics, where 3 of them have a lot of relevant pages and 3 of them do not have much. In order to compare 3 different algorithms (1 without learning and 2 that uses reinforcement learning), for each topic they run the crawlers until they collect 10000 pages. Then they use the number of relevant pages as a performance metric and compare the algorithms.

## Focused crawling for structured data
### Abstract
The Web is rapidly transforming from a pure document collection to the largest connected public data space. Semantic annotations of web pages make it notably easier to extract and reuse data and are increasingly used by both search engines and social media sites to provide better search experiences through rich snippets, faceted search, task completion, etc. In our work, we study the novel problem of crawling structured data embedded inside HTML pages. We describe Anthelion, the first focused crawler addressing this task. We propose new methods of focused crawling specifically designed for collecting data-rich pages with greater efficiency. In particular, we propose a novel combination of online learning and bandit-based explore/exploit approaches to predict data-rich web pages based on the context of the page as well as using feedback from the extraction of metadata from previously seen pages. We show that these techniques significantly outperform state-of-the-art approaches for focused crawling, measured as the ratio of relevant pages and non-relevant pages collected within a given budget.
### Summary
Anthelion is a focused Web crawler and its goal is to find web pages that contain structured data embedded in them (e.g. schema.org markup). They use online learning to predict which links may contain structured data, this is possible because after downloading a link it can be seen whether the page contains any structured data. To cope with exploration/exploitation problem, they model the hosts as arms in a multi armed bandit setting and evaluate different bandit functions using λ-Greedy selection method.
The datasets used for the experiments are extracted from the publicly accessible dataset provided by the Common Crawl Foundation. In the first part of the experiments, they compare online and batch learning(percentage of relevant fetched pages during crawling) and the results show that online learning performs better at the end of the crawl. They also compare different bandit functions and lambda values (including decaying λ).


## Twitterecho: A distributed focused crawler to support open research with twitter data (-)
### Abstract
Modern social network analysis relies on vast quantities of data to infer new knowledge about human relations and communication. In this paper we describe TwitterEcho, an open source Twitter crawler for supporting this kind of research, which is characterized by a modular distributed architecture. Our crawler enables researchers to continuously collect data from particular user communities, while respecting Twitter's imposed limits. We present the core modules of the crawling server, some of which were specifically designed to focus the crawl on the Portuguese Twittosphere. Additional modules can be easily implemented, thus changing the focus to a different community. Our evaluation of the system shows high crawling performance and coverage.
### Summary
TwitterEcho is an open-source Twitter crawler that helps researchers collect large amount of data while respecting Twitter’s rate limits. Unfortunately the code is not available. It has a modular and distributed architecture. They used TwitterEcho to find people from Portuguese Twittosphere, however the modules can be changed depending on the research interest. The paper lacks mathematical background and the aim of the crawler is to collect huge amount of data with the help of a distributed system rather than focusing on a community with same features.

## Inferring gender of a twitter user using celebrities it follows (-)
### Abstract
This paper addresses the task of user gender classification in social media, with an application to Twitter. The approach automatically predicts gender by leveraging observable information such as the tweet behavior, linguistic content of the user's Twitter feed and the celebrities followed by the user. This paper first evaluates linguistic content based features using LIWC dictionary and popular neighborhood features using Wikipedia and Freebase. Then augments both features which yielded a significant increase in the accuracy for gender prediction. Results show that rich linguistic features combined with popular neighborhood prove valuables and promising for additional user classification needs.
### Summary
In this work the authrors try to infer a users gender based on features obtained from her tweets and also from celebrities that she follows (age of celebrity, gender of celebrity ...). A list of celebrity users is obtained for this task. They use SVM-based classifiers for gender classification. The network structure is initially known and is used to create features.
They use a previously collected database which contains 131 male and 134 female labeled users. Using 10-fold cross validation, they measure the performance of the SVM classifier in terms of accuracy and obtain 85.67%.

## Prism: Profession identification in social media (?)
### Abstract
Profession is an important social attribute of people. It plays a crucial role in commercial services such as personalized recommendation and targeted advertising. In practice, profession information is usually unavailable due to privacy and other reasons. In this article, we explore the task of identifying user professions according to their behaviors in social media. The task confronts the following challenges that make it non-trivial: how to incorporate heterogeneous information of user behaviors, how to effectively utilize both labeled and unlabeled data, and how to exploit community structure. To address these challenges, we present a framework called Profession Identification in Social Media. It takes advantage of both personal information and community structure of users in the following aspects: (1) We present a cascaded two-level classifier with heterogeneous personal features to measure the confidence of users belonging to different professions. (2) We present a multi-training process to take advantages of both labeled and unlabeled data to enhance classification performance. (3) We design a profession identification method synthetically considering the confidences from personal features and community structure. We collect a real-world dataset to conduct experiments, and experimental results demonstrate the significant effectiveness of our method compared with other baseline methods. By applying prediction on large-scale users, we also analyze characteristics of microblog users, finding that there are significant diversities among users of different professions in demographics, social network structures, and linguistic styles.
### Summary
The main goal of this work is to identify profession of social media users. They divide the information from Twitter into several different sources and and then use a cascaded two level classifier for prediction. They also use network structure for refining the profession identification but they do not use crawling.
For experiments they use a database with more than 60,000 manually annotated microblog users from a microblog service in China. 14 different professions are selected such as art, government, etc ... The dataset is divided into test and training sets, other than that, macro-averaging precision/recall/F-Measure is used for evaluation metrics. They claim that all metrics used for evaluation are larger than 80%.